{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "210e4ba0",
   "metadata": {},
   "source": [
    "**Importing required libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d272a039",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "pd.set_option('display.max_columns',None)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e2b936",
   "metadata": {},
   "source": [
    "**Load Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f7bbd4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>radius_se</th>\n",
       "      <th>texture_se</th>\n",
       "      <th>perimeter_se</th>\n",
       "      <th>area_se</th>\n",
       "      <th>smoothness_se</th>\n",
       "      <th>compactness_se</th>\n",
       "      <th>concavity_se</th>\n",
       "      <th>concave points_se</th>\n",
       "      <th>symmetry_se</th>\n",
       "      <th>fractal_dimension_se</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>1.0950</td>\n",
       "      <td>0.9053</td>\n",
       "      <td>8.589</td>\n",
       "      <td>153.40</td>\n",
       "      <td>0.006399</td>\n",
       "      <td>0.04904</td>\n",
       "      <td>0.05373</td>\n",
       "      <td>0.01587</td>\n",
       "      <td>0.03003</td>\n",
       "      <td>0.006193</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>0.5435</td>\n",
       "      <td>0.7339</td>\n",
       "      <td>3.398</td>\n",
       "      <td>74.08</td>\n",
       "      <td>0.005225</td>\n",
       "      <td>0.01308</td>\n",
       "      <td>0.01860</td>\n",
       "      <td>0.01340</td>\n",
       "      <td>0.01389</td>\n",
       "      <td>0.003532</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>0.7456</td>\n",
       "      <td>0.7869</td>\n",
       "      <td>4.585</td>\n",
       "      <td>94.03</td>\n",
       "      <td>0.006150</td>\n",
       "      <td>0.04006</td>\n",
       "      <td>0.03832</td>\n",
       "      <td>0.02058</td>\n",
       "      <td>0.02250</td>\n",
       "      <td>0.004571</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>0.4956</td>\n",
       "      <td>1.1560</td>\n",
       "      <td>3.445</td>\n",
       "      <td>27.23</td>\n",
       "      <td>0.009110</td>\n",
       "      <td>0.07458</td>\n",
       "      <td>0.05661</td>\n",
       "      <td>0.01867</td>\n",
       "      <td>0.05963</td>\n",
       "      <td>0.009208</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>0.7572</td>\n",
       "      <td>0.7813</td>\n",
       "      <td>5.438</td>\n",
       "      <td>94.44</td>\n",
       "      <td>0.011490</td>\n",
       "      <td>0.02461</td>\n",
       "      <td>0.05688</td>\n",
       "      <td>0.01885</td>\n",
       "      <td>0.01756</td>\n",
       "      <td>0.005115</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>926424</td>\n",
       "      <td>M</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>1.1760</td>\n",
       "      <td>1.2560</td>\n",
       "      <td>7.673</td>\n",
       "      <td>158.70</td>\n",
       "      <td>0.010300</td>\n",
       "      <td>0.02891</td>\n",
       "      <td>0.05198</td>\n",
       "      <td>0.02454</td>\n",
       "      <td>0.01114</td>\n",
       "      <td>0.004239</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>926682</td>\n",
       "      <td>M</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>0.7655</td>\n",
       "      <td>2.4630</td>\n",
       "      <td>5.203</td>\n",
       "      <td>99.04</td>\n",
       "      <td>0.005769</td>\n",
       "      <td>0.02423</td>\n",
       "      <td>0.03950</td>\n",
       "      <td>0.01678</td>\n",
       "      <td>0.01898</td>\n",
       "      <td>0.002498</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>926954</td>\n",
       "      <td>M</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>0.4564</td>\n",
       "      <td>1.0750</td>\n",
       "      <td>3.425</td>\n",
       "      <td>48.55</td>\n",
       "      <td>0.005903</td>\n",
       "      <td>0.03731</td>\n",
       "      <td>0.04730</td>\n",
       "      <td>0.01557</td>\n",
       "      <td>0.01318</td>\n",
       "      <td>0.003892</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>927241</td>\n",
       "      <td>M</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>0.7260</td>\n",
       "      <td>1.5950</td>\n",
       "      <td>5.772</td>\n",
       "      <td>86.22</td>\n",
       "      <td>0.006522</td>\n",
       "      <td>0.06158</td>\n",
       "      <td>0.07117</td>\n",
       "      <td>0.01664</td>\n",
       "      <td>0.02324</td>\n",
       "      <td>0.006185</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>92751</td>\n",
       "      <td>B</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>0.3857</td>\n",
       "      <td>1.4280</td>\n",
       "      <td>2.548</td>\n",
       "      <td>19.15</td>\n",
       "      <td>0.007189</td>\n",
       "      <td>0.00466</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.02676</td>\n",
       "      <td>0.002783</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0      842302         M        17.99         10.38          122.80     1001.0   \n",
       "1      842517         M        20.57         17.77          132.90     1326.0   \n",
       "2    84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3    84348301         M        11.42         20.38           77.58      386.1   \n",
       "4    84358402         M        20.29         14.34          135.10     1297.0   \n",
       "..        ...       ...          ...           ...             ...        ...   \n",
       "564    926424         M        21.56         22.39          142.00     1479.0   \n",
       "565    926682         M        20.13         28.25          131.20     1261.0   \n",
       "566    926954         M        16.60         28.08          108.30      858.1   \n",
       "567    927241         M        20.60         29.33          140.10     1265.0   \n",
       "568     92751         B         7.76         24.54           47.92      181.0   \n",
       "\n",
       "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0            0.11840           0.27760         0.30010              0.14710   \n",
       "1            0.08474           0.07864         0.08690              0.07017   \n",
       "2            0.10960           0.15990         0.19740              0.12790   \n",
       "3            0.14250           0.28390         0.24140              0.10520   \n",
       "4            0.10030           0.13280         0.19800              0.10430   \n",
       "..               ...               ...             ...                  ...   \n",
       "564          0.11100           0.11590         0.24390              0.13890   \n",
       "565          0.09780           0.10340         0.14400              0.09791   \n",
       "566          0.08455           0.10230         0.09251              0.05302   \n",
       "567          0.11780           0.27700         0.35140              0.15200   \n",
       "568          0.05263           0.04362         0.00000              0.00000   \n",
       "\n",
       "     symmetry_mean  fractal_dimension_mean  radius_se  texture_se  \\\n",
       "0           0.2419                 0.07871     1.0950      0.9053   \n",
       "1           0.1812                 0.05667     0.5435      0.7339   \n",
       "2           0.2069                 0.05999     0.7456      0.7869   \n",
       "3           0.2597                 0.09744     0.4956      1.1560   \n",
       "4           0.1809                 0.05883     0.7572      0.7813   \n",
       "..             ...                     ...        ...         ...   \n",
       "564         0.1726                 0.05623     1.1760      1.2560   \n",
       "565         0.1752                 0.05533     0.7655      2.4630   \n",
       "566         0.1590                 0.05648     0.4564      1.0750   \n",
       "567         0.2397                 0.07016     0.7260      1.5950   \n",
       "568         0.1587                 0.05884     0.3857      1.4280   \n",
       "\n",
       "     perimeter_se  area_se  smoothness_se  compactness_se  concavity_se  \\\n",
       "0           8.589   153.40       0.006399         0.04904       0.05373   \n",
       "1           3.398    74.08       0.005225         0.01308       0.01860   \n",
       "2           4.585    94.03       0.006150         0.04006       0.03832   \n",
       "3           3.445    27.23       0.009110         0.07458       0.05661   \n",
       "4           5.438    94.44       0.011490         0.02461       0.05688   \n",
       "..            ...      ...            ...             ...           ...   \n",
       "564         7.673   158.70       0.010300         0.02891       0.05198   \n",
       "565         5.203    99.04       0.005769         0.02423       0.03950   \n",
       "566         3.425    48.55       0.005903         0.03731       0.04730   \n",
       "567         5.772    86.22       0.006522         0.06158       0.07117   \n",
       "568         2.548    19.15       0.007189         0.00466       0.00000   \n",
       "\n",
       "     concave points_se  symmetry_se  fractal_dimension_se  radius_worst  \\\n",
       "0              0.01587      0.03003              0.006193        25.380   \n",
       "1              0.01340      0.01389              0.003532        24.990   \n",
       "2              0.02058      0.02250              0.004571        23.570   \n",
       "3              0.01867      0.05963              0.009208        14.910   \n",
       "4              0.01885      0.01756              0.005115        22.540   \n",
       "..                 ...          ...                   ...           ...   \n",
       "564            0.02454      0.01114              0.004239        25.450   \n",
       "565            0.01678      0.01898              0.002498        23.690   \n",
       "566            0.01557      0.01318              0.003892        18.980   \n",
       "567            0.01664      0.02324              0.006185        25.740   \n",
       "568            0.00000      0.02676              0.002783         9.456   \n",
       "\n",
       "     texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0            17.33           184.60      2019.0           0.16220   \n",
       "1            23.41           158.80      1956.0           0.12380   \n",
       "2            25.53           152.50      1709.0           0.14440   \n",
       "3            26.50            98.87       567.7           0.20980   \n",
       "4            16.67           152.20      1575.0           0.13740   \n",
       "..             ...              ...         ...               ...   \n",
       "564          26.40           166.10      2027.0           0.14100   \n",
       "565          38.25           155.00      1731.0           0.11660   \n",
       "566          34.12           126.70      1124.0           0.11390   \n",
       "567          39.42           184.60      1821.0           0.16500   \n",
       "568          30.37            59.16       268.6           0.08996   \n",
       "\n",
       "     compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0              0.66560           0.7119                0.2654          0.4601   \n",
       "1              0.18660           0.2416                0.1860          0.2750   \n",
       "2              0.42450           0.4504                0.2430          0.3613   \n",
       "3              0.86630           0.6869                0.2575          0.6638   \n",
       "4              0.20500           0.4000                0.1625          0.2364   \n",
       "..                 ...              ...                   ...             ...   \n",
       "564            0.21130           0.4107                0.2216          0.2060   \n",
       "565            0.19220           0.3215                0.1628          0.2572   \n",
       "566            0.30940           0.3403                0.1418          0.2218   \n",
       "567            0.86810           0.9387                0.2650          0.4087   \n",
       "568            0.06444           0.0000                0.0000          0.2871   \n",
       "\n",
       "     fractal_dimension_worst  Unnamed: 32  \n",
       "0                    0.11890          NaN  \n",
       "1                    0.08902          NaN  \n",
       "2                    0.08758          NaN  \n",
       "3                    0.17300          NaN  \n",
       "4                    0.07678          NaN  \n",
       "..                       ...          ...  \n",
       "564                  0.07115          NaN  \n",
       "565                  0.06637          NaN  \n",
       "566                  0.07820          NaN  \n",
       "567                  0.12400          NaN  \n",
       "568                  0.07039          NaN  \n",
       "\n",
       "[569 rows x 33 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('breastCancer.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28ef5cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 33 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   id                       569 non-null    int64  \n",
      " 1   diagnosis                569 non-null    object \n",
      " 2   radius_mean              569 non-null    float64\n",
      " 3   texture_mean             569 non-null    float64\n",
      " 4   perimeter_mean           569 non-null    float64\n",
      " 5   area_mean                569 non-null    float64\n",
      " 6   smoothness_mean          569 non-null    float64\n",
      " 7   compactness_mean         569 non-null    float64\n",
      " 8   concavity_mean           569 non-null    float64\n",
      " 9   concave points_mean      569 non-null    float64\n",
      " 10  symmetry_mean            569 non-null    float64\n",
      " 11  fractal_dimension_mean   569 non-null    float64\n",
      " 12  radius_se                569 non-null    float64\n",
      " 13  texture_se               569 non-null    float64\n",
      " 14  perimeter_se             569 non-null    float64\n",
      " 15  area_se                  569 non-null    float64\n",
      " 16  smoothness_se            569 non-null    float64\n",
      " 17  compactness_se           569 non-null    float64\n",
      " 18  concavity_se             569 non-null    float64\n",
      " 19  concave points_se        569 non-null    float64\n",
      " 20  symmetry_se              569 non-null    float64\n",
      " 21  fractal_dimension_se     569 non-null    float64\n",
      " 22  radius_worst             569 non-null    float64\n",
      " 23  texture_worst            569 non-null    float64\n",
      " 24  perimeter_worst          569 non-null    float64\n",
      " 25  area_worst               569 non-null    float64\n",
      " 26  smoothness_worst         569 non-null    float64\n",
      " 27  compactness_worst        569 non-null    float64\n",
      " 28  concavity_worst          569 non-null    float64\n",
      " 29  concave points_worst     569 non-null    float64\n",
      " 30  symmetry_worst           569 non-null    float64\n",
      " 31  fractal_dimension_worst  569 non-null    float64\n",
      " 32  Unnamed: 32              0 non-null      float64\n",
      "dtypes: float64(31), int64(1), object(1)\n",
      "memory usage: 146.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c19e8dec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                           0\n",
       "diagnosis                    0\n",
       "radius_mean                  0\n",
       "texture_mean                 0\n",
       "perimeter_mean               0\n",
       "area_mean                    0\n",
       "smoothness_mean              0\n",
       "compactness_mean             0\n",
       "concavity_mean               0\n",
       "concave points_mean          0\n",
       "symmetry_mean                0\n",
       "fractal_dimension_mean       0\n",
       "radius_se                    0\n",
       "texture_se                   0\n",
       "perimeter_se                 0\n",
       "area_se                      0\n",
       "smoothness_se                0\n",
       "compactness_se               0\n",
       "concavity_se                 0\n",
       "concave points_se            0\n",
       "symmetry_se                  0\n",
       "fractal_dimension_se         0\n",
       "radius_worst                 0\n",
       "texture_worst                0\n",
       "perimeter_worst              0\n",
       "area_worst                   0\n",
       "smoothness_worst             0\n",
       "compactness_worst            0\n",
       "concavity_worst              0\n",
       "concave points_worst         0\n",
       "symmetry_worst               0\n",
       "fractal_dimension_worst      0\n",
       "Unnamed: 32                569\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "751e472a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>radius_se</th>\n",
       "      <th>texture_se</th>\n",
       "      <th>perimeter_se</th>\n",
       "      <th>area_se</th>\n",
       "      <th>smoothness_se</th>\n",
       "      <th>compactness_se</th>\n",
       "      <th>concavity_se</th>\n",
       "      <th>concave points_se</th>\n",
       "      <th>symmetry_se</th>\n",
       "      <th>fractal_dimension_se</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>1.0950</td>\n",
       "      <td>0.9053</td>\n",
       "      <td>8.589</td>\n",
       "      <td>153.40</td>\n",
       "      <td>0.006399</td>\n",
       "      <td>0.04904</td>\n",
       "      <td>0.05373</td>\n",
       "      <td>0.01587</td>\n",
       "      <td>0.03003</td>\n",
       "      <td>0.006193</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>0.5435</td>\n",
       "      <td>0.7339</td>\n",
       "      <td>3.398</td>\n",
       "      <td>74.08</td>\n",
       "      <td>0.005225</td>\n",
       "      <td>0.01308</td>\n",
       "      <td>0.01860</td>\n",
       "      <td>0.01340</td>\n",
       "      <td>0.01389</td>\n",
       "      <td>0.003532</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>0.7456</td>\n",
       "      <td>0.7869</td>\n",
       "      <td>4.585</td>\n",
       "      <td>94.03</td>\n",
       "      <td>0.006150</td>\n",
       "      <td>0.04006</td>\n",
       "      <td>0.03832</td>\n",
       "      <td>0.02058</td>\n",
       "      <td>0.02250</td>\n",
       "      <td>0.004571</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>0.4956</td>\n",
       "      <td>1.1560</td>\n",
       "      <td>3.445</td>\n",
       "      <td>27.23</td>\n",
       "      <td>0.009110</td>\n",
       "      <td>0.07458</td>\n",
       "      <td>0.05661</td>\n",
       "      <td>0.01867</td>\n",
       "      <td>0.05963</td>\n",
       "      <td>0.009208</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>0.7572</td>\n",
       "      <td>0.7813</td>\n",
       "      <td>5.438</td>\n",
       "      <td>94.44</td>\n",
       "      <td>0.011490</td>\n",
       "      <td>0.02461</td>\n",
       "      <td>0.05688</td>\n",
       "      <td>0.01885</td>\n",
       "      <td>0.01756</td>\n",
       "      <td>0.005115</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>M</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>1.1760</td>\n",
       "      <td>1.2560</td>\n",
       "      <td>7.673</td>\n",
       "      <td>158.70</td>\n",
       "      <td>0.010300</td>\n",
       "      <td>0.02891</td>\n",
       "      <td>0.05198</td>\n",
       "      <td>0.02454</td>\n",
       "      <td>0.01114</td>\n",
       "      <td>0.004239</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>M</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>0.7655</td>\n",
       "      <td>2.4630</td>\n",
       "      <td>5.203</td>\n",
       "      <td>99.04</td>\n",
       "      <td>0.005769</td>\n",
       "      <td>0.02423</td>\n",
       "      <td>0.03950</td>\n",
       "      <td>0.01678</td>\n",
       "      <td>0.01898</td>\n",
       "      <td>0.002498</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>M</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>0.4564</td>\n",
       "      <td>1.0750</td>\n",
       "      <td>3.425</td>\n",
       "      <td>48.55</td>\n",
       "      <td>0.005903</td>\n",
       "      <td>0.03731</td>\n",
       "      <td>0.04730</td>\n",
       "      <td>0.01557</td>\n",
       "      <td>0.01318</td>\n",
       "      <td>0.003892</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>M</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>0.7260</td>\n",
       "      <td>1.5950</td>\n",
       "      <td>5.772</td>\n",
       "      <td>86.22</td>\n",
       "      <td>0.006522</td>\n",
       "      <td>0.06158</td>\n",
       "      <td>0.07117</td>\n",
       "      <td>0.01664</td>\n",
       "      <td>0.02324</td>\n",
       "      <td>0.006185</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>B</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>0.3857</td>\n",
       "      <td>1.4280</td>\n",
       "      <td>2.548</td>\n",
       "      <td>19.15</td>\n",
       "      <td>0.007189</td>\n",
       "      <td>0.00466</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.02676</td>\n",
       "      <td>0.002783</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0           M        17.99         10.38          122.80     1001.0   \n",
       "1           M        20.57         17.77          132.90     1326.0   \n",
       "2           M        19.69         21.25          130.00     1203.0   \n",
       "3           M        11.42         20.38           77.58      386.1   \n",
       "4           M        20.29         14.34          135.10     1297.0   \n",
       "..        ...          ...           ...             ...        ...   \n",
       "564         M        21.56         22.39          142.00     1479.0   \n",
       "565         M        20.13         28.25          131.20     1261.0   \n",
       "566         M        16.60         28.08          108.30      858.1   \n",
       "567         M        20.60         29.33          140.10     1265.0   \n",
       "568         B         7.76         24.54           47.92      181.0   \n",
       "\n",
       "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0            0.11840           0.27760         0.30010              0.14710   \n",
       "1            0.08474           0.07864         0.08690              0.07017   \n",
       "2            0.10960           0.15990         0.19740              0.12790   \n",
       "3            0.14250           0.28390         0.24140              0.10520   \n",
       "4            0.10030           0.13280         0.19800              0.10430   \n",
       "..               ...               ...             ...                  ...   \n",
       "564          0.11100           0.11590         0.24390              0.13890   \n",
       "565          0.09780           0.10340         0.14400              0.09791   \n",
       "566          0.08455           0.10230         0.09251              0.05302   \n",
       "567          0.11780           0.27700         0.35140              0.15200   \n",
       "568          0.05263           0.04362         0.00000              0.00000   \n",
       "\n",
       "     symmetry_mean  fractal_dimension_mean  radius_se  texture_se  \\\n",
       "0           0.2419                 0.07871     1.0950      0.9053   \n",
       "1           0.1812                 0.05667     0.5435      0.7339   \n",
       "2           0.2069                 0.05999     0.7456      0.7869   \n",
       "3           0.2597                 0.09744     0.4956      1.1560   \n",
       "4           0.1809                 0.05883     0.7572      0.7813   \n",
       "..             ...                     ...        ...         ...   \n",
       "564         0.1726                 0.05623     1.1760      1.2560   \n",
       "565         0.1752                 0.05533     0.7655      2.4630   \n",
       "566         0.1590                 0.05648     0.4564      1.0750   \n",
       "567         0.2397                 0.07016     0.7260      1.5950   \n",
       "568         0.1587                 0.05884     0.3857      1.4280   \n",
       "\n",
       "     perimeter_se  area_se  smoothness_se  compactness_se  concavity_se  \\\n",
       "0           8.589   153.40       0.006399         0.04904       0.05373   \n",
       "1           3.398    74.08       0.005225         0.01308       0.01860   \n",
       "2           4.585    94.03       0.006150         0.04006       0.03832   \n",
       "3           3.445    27.23       0.009110         0.07458       0.05661   \n",
       "4           5.438    94.44       0.011490         0.02461       0.05688   \n",
       "..            ...      ...            ...             ...           ...   \n",
       "564         7.673   158.70       0.010300         0.02891       0.05198   \n",
       "565         5.203    99.04       0.005769         0.02423       0.03950   \n",
       "566         3.425    48.55       0.005903         0.03731       0.04730   \n",
       "567         5.772    86.22       0.006522         0.06158       0.07117   \n",
       "568         2.548    19.15       0.007189         0.00466       0.00000   \n",
       "\n",
       "     concave points_se  symmetry_se  fractal_dimension_se  radius_worst  \\\n",
       "0              0.01587      0.03003              0.006193        25.380   \n",
       "1              0.01340      0.01389              0.003532        24.990   \n",
       "2              0.02058      0.02250              0.004571        23.570   \n",
       "3              0.01867      0.05963              0.009208        14.910   \n",
       "4              0.01885      0.01756              0.005115        22.540   \n",
       "..                 ...          ...                   ...           ...   \n",
       "564            0.02454      0.01114              0.004239        25.450   \n",
       "565            0.01678      0.01898              0.002498        23.690   \n",
       "566            0.01557      0.01318              0.003892        18.980   \n",
       "567            0.01664      0.02324              0.006185        25.740   \n",
       "568            0.00000      0.02676              0.002783         9.456   \n",
       "\n",
       "     texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0            17.33           184.60      2019.0           0.16220   \n",
       "1            23.41           158.80      1956.0           0.12380   \n",
       "2            25.53           152.50      1709.0           0.14440   \n",
       "3            26.50            98.87       567.7           0.20980   \n",
       "4            16.67           152.20      1575.0           0.13740   \n",
       "..             ...              ...         ...               ...   \n",
       "564          26.40           166.10      2027.0           0.14100   \n",
       "565          38.25           155.00      1731.0           0.11660   \n",
       "566          34.12           126.70      1124.0           0.11390   \n",
       "567          39.42           184.60      1821.0           0.16500   \n",
       "568          30.37            59.16       268.6           0.08996   \n",
       "\n",
       "     compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0              0.66560           0.7119                0.2654          0.4601   \n",
       "1              0.18660           0.2416                0.1860          0.2750   \n",
       "2              0.42450           0.4504                0.2430          0.3613   \n",
       "3              0.86630           0.6869                0.2575          0.6638   \n",
       "4              0.20500           0.4000                0.1625          0.2364   \n",
       "..                 ...              ...                   ...             ...   \n",
       "564            0.21130           0.4107                0.2216          0.2060   \n",
       "565            0.19220           0.3215                0.1628          0.2572   \n",
       "566            0.30940           0.3403                0.1418          0.2218   \n",
       "567            0.86810           0.9387                0.2650          0.4087   \n",
       "568            0.06444           0.0000                0.0000          0.2871   \n",
       "\n",
       "     fractal_dimension_worst  \n",
       "0                    0.11890  \n",
       "1                    0.08902  \n",
       "2                    0.08758  \n",
       "3                    0.17300  \n",
       "4                    0.07678  \n",
       "..                       ...  \n",
       "564                  0.07115  \n",
       "565                  0.06637  \n",
       "566                  0.07820  \n",
       "567                  0.12400  \n",
       "568                  0.07039  \n",
       "\n",
       "[569 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Removing Unnecessary columns from dataset\n",
    "\n",
    "df.drop(['id', 'Unnamed: 32'],axis = 1, inplace = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9a7d09",
   "metadata": {},
   "source": [
    "**We see there's only 1 column, which has object object datatype, so we'll convert into int**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "589c9122",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['diagnosis'].replace({'M':0, 'B':1},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad57cfe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>radius_se</th>\n",
       "      <th>texture_se</th>\n",
       "      <th>perimeter_se</th>\n",
       "      <th>area_se</th>\n",
       "      <th>smoothness_se</th>\n",
       "      <th>compactness_se</th>\n",
       "      <th>concavity_se</th>\n",
       "      <th>concave points_se</th>\n",
       "      <th>symmetry_se</th>\n",
       "      <th>fractal_dimension_se</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>568.000000</td>\n",
       "      <td>568.000000</td>\n",
       "      <td>568.000000</td>\n",
       "      <td>568.000000</td>\n",
       "      <td>568.000000</td>\n",
       "      <td>568.000000</td>\n",
       "      <td>568.000000</td>\n",
       "      <td>568.000000</td>\n",
       "      <td>568.000000</td>\n",
       "      <td>568.000000</td>\n",
       "      <td>568.000000</td>\n",
       "      <td>568.000000</td>\n",
       "      <td>568.000000</td>\n",
       "      <td>568.000000</td>\n",
       "      <td>568.000000</td>\n",
       "      <td>568.000000</td>\n",
       "      <td>568.000000</td>\n",
       "      <td>568.000000</td>\n",
       "      <td>568.000000</td>\n",
       "      <td>568.000000</td>\n",
       "      <td>568.000000</td>\n",
       "      <td>568.00000</td>\n",
       "      <td>568.000000</td>\n",
       "      <td>568.000000</td>\n",
       "      <td>568.000000</td>\n",
       "      <td>568.000000</td>\n",
       "      <td>568.000000</td>\n",
       "      <td>568.000000</td>\n",
       "      <td>568.000000</td>\n",
       "      <td>568.000000</td>\n",
       "      <td>568.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.628521</td>\n",
       "      <td>14.120491</td>\n",
       "      <td>19.305335</td>\n",
       "      <td>91.914754</td>\n",
       "      <td>654.279754</td>\n",
       "      <td>0.096321</td>\n",
       "      <td>0.104036</td>\n",
       "      <td>0.088427</td>\n",
       "      <td>0.048746</td>\n",
       "      <td>0.181055</td>\n",
       "      <td>0.062770</td>\n",
       "      <td>0.403958</td>\n",
       "      <td>1.217402</td>\n",
       "      <td>2.855984</td>\n",
       "      <td>40.138025</td>\n",
       "      <td>0.007042</td>\n",
       "      <td>0.025437</td>\n",
       "      <td>0.031855</td>\n",
       "      <td>0.011789</td>\n",
       "      <td>0.020526</td>\n",
       "      <td>0.003791</td>\n",
       "      <td>16.25315</td>\n",
       "      <td>25.691919</td>\n",
       "      <td>107.125053</td>\n",
       "      <td>878.578873</td>\n",
       "      <td>0.132316</td>\n",
       "      <td>0.253541</td>\n",
       "      <td>0.271414</td>\n",
       "      <td>0.114341</td>\n",
       "      <td>0.289776</td>\n",
       "      <td>0.083884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.483626</td>\n",
       "      <td>3.523416</td>\n",
       "      <td>4.288506</td>\n",
       "      <td>24.285848</td>\n",
       "      <td>351.923751</td>\n",
       "      <td>0.014046</td>\n",
       "      <td>0.052355</td>\n",
       "      <td>0.079294</td>\n",
       "      <td>0.038617</td>\n",
       "      <td>0.027319</td>\n",
       "      <td>0.007035</td>\n",
       "      <td>0.276038</td>\n",
       "      <td>0.551979</td>\n",
       "      <td>2.009288</td>\n",
       "      <td>45.282406</td>\n",
       "      <td>0.003005</td>\n",
       "      <td>0.017897</td>\n",
       "      <td>0.030199</td>\n",
       "      <td>0.006173</td>\n",
       "      <td>0.008264</td>\n",
       "      <td>0.002646</td>\n",
       "      <td>4.82232</td>\n",
       "      <td>6.141662</td>\n",
       "      <td>33.474687</td>\n",
       "      <td>567.846267</td>\n",
       "      <td>0.022818</td>\n",
       "      <td>0.156523</td>\n",
       "      <td>0.207989</td>\n",
       "      <td>0.065484</td>\n",
       "      <td>0.061508</td>\n",
       "      <td>0.018017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>0.049960</td>\n",
       "      <td>0.111500</td>\n",
       "      <td>0.360200</td>\n",
       "      <td>0.757000</td>\n",
       "      <td>6.802000</td>\n",
       "      <td>0.001713</td>\n",
       "      <td>0.002252</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007882</td>\n",
       "      <td>0.000895</td>\n",
       "      <td>7.93000</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.697500</td>\n",
       "      <td>16.177500</td>\n",
       "      <td>75.135000</td>\n",
       "      <td>420.175000</td>\n",
       "      <td>0.086290</td>\n",
       "      <td>0.064815</td>\n",
       "      <td>0.029540</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>0.057697</td>\n",
       "      <td>0.232375</td>\n",
       "      <td>0.833150</td>\n",
       "      <td>1.605000</td>\n",
       "      <td>17.850000</td>\n",
       "      <td>0.005166</td>\n",
       "      <td>0.013048</td>\n",
       "      <td>0.015062</td>\n",
       "      <td>0.007634</td>\n",
       "      <td>0.015128</td>\n",
       "      <td>0.002244</td>\n",
       "      <td>13.01000</td>\n",
       "      <td>21.095000</td>\n",
       "      <td>84.102500</td>\n",
       "      <td>514.975000</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.146900</td>\n",
       "      <td>0.114475</td>\n",
       "      <td>0.064730</td>\n",
       "      <td>0.250350</td>\n",
       "      <td>0.071412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.355000</td>\n",
       "      <td>18.855000</td>\n",
       "      <td>86.210000</td>\n",
       "      <td>548.750000</td>\n",
       "      <td>0.095865</td>\n",
       "      <td>0.092525</td>\n",
       "      <td>0.061400</td>\n",
       "      <td>0.033455</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>0.061515</td>\n",
       "      <td>0.323950</td>\n",
       "      <td>1.109500</td>\n",
       "      <td>2.285500</td>\n",
       "      <td>24.485000</td>\n",
       "      <td>0.006374</td>\n",
       "      <td>0.020435</td>\n",
       "      <td>0.025875</td>\n",
       "      <td>0.010920</td>\n",
       "      <td>0.018725</td>\n",
       "      <td>0.003162</td>\n",
       "      <td>14.96500</td>\n",
       "      <td>25.425000</td>\n",
       "      <td>97.655000</td>\n",
       "      <td>685.550000</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.211850</td>\n",
       "      <td>0.226550</td>\n",
       "      <td>0.099840</td>\n",
       "      <td>0.282050</td>\n",
       "      <td>0.080015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.780000</td>\n",
       "      <td>21.802500</td>\n",
       "      <td>103.875000</td>\n",
       "      <td>782.625000</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.129650</td>\n",
       "      <td>0.073730</td>\n",
       "      <td>0.195625</td>\n",
       "      <td>0.066120</td>\n",
       "      <td>0.477325</td>\n",
       "      <td>1.474250</td>\n",
       "      <td>3.336750</td>\n",
       "      <td>45.017500</td>\n",
       "      <td>0.008151</td>\n",
       "      <td>0.032218</td>\n",
       "      <td>0.041765</td>\n",
       "      <td>0.014710</td>\n",
       "      <td>0.023397</td>\n",
       "      <td>0.004526</td>\n",
       "      <td>18.76750</td>\n",
       "      <td>29.757500</td>\n",
       "      <td>125.175000</td>\n",
       "      <td>1073.500000</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.337600</td>\n",
       "      <td>0.381400</td>\n",
       "      <td>0.161325</td>\n",
       "      <td>0.317675</td>\n",
       "      <td>0.092065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>28.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>0.097440</td>\n",
       "      <td>2.873000</td>\n",
       "      <td>4.885000</td>\n",
       "      <td>21.980000</td>\n",
       "      <td>542.200000</td>\n",
       "      <td>0.031130</td>\n",
       "      <td>0.135400</td>\n",
       "      <td>0.396000</td>\n",
       "      <td>0.052790</td>\n",
       "      <td>0.078950</td>\n",
       "      <td>0.029840</td>\n",
       "      <td>36.04000</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>251.200000</td>\n",
       "      <td>4254.000000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.252000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.207500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        diagnosis  radius_mean  texture_mean  perimeter_mean    area_mean  \\\n",
       "count  568.000000   568.000000    568.000000      568.000000   568.000000   \n",
       "mean     0.628521    14.120491     19.305335       91.914754   654.279754   \n",
       "std      0.483626     3.523416      4.288506       24.285848   351.923751   \n",
       "min      0.000000     6.981000      9.710000       43.790000   143.500000   \n",
       "25%      0.000000    11.697500     16.177500       75.135000   420.175000   \n",
       "50%      1.000000    13.355000     18.855000       86.210000   548.750000   \n",
       "75%      1.000000    15.780000     21.802500      103.875000   782.625000   \n",
       "max      1.000000    28.110000     39.280000      188.500000  2501.000000   \n",
       "\n",
       "       smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "count       568.000000        568.000000      568.000000           568.000000   \n",
       "mean          0.096321          0.104036        0.088427             0.048746   \n",
       "std           0.014046          0.052355        0.079294             0.038617   \n",
       "min           0.052630          0.019380        0.000000             0.000000   \n",
       "25%           0.086290          0.064815        0.029540             0.020310   \n",
       "50%           0.095865          0.092525        0.061400             0.033455   \n",
       "75%           0.105300          0.130400        0.129650             0.073730   \n",
       "max           0.163400          0.345400        0.426800             0.201200   \n",
       "\n",
       "       symmetry_mean  fractal_dimension_mean   radius_se  texture_se  \\\n",
       "count     568.000000              568.000000  568.000000  568.000000   \n",
       "mean        0.181055                0.062770    0.403958    1.217402   \n",
       "std         0.027319                0.007035    0.276038    0.551979   \n",
       "min         0.106000                0.049960    0.111500    0.360200   \n",
       "25%         0.161900                0.057697    0.232375    0.833150   \n",
       "50%         0.179200                0.061515    0.323950    1.109500   \n",
       "75%         0.195625                0.066120    0.477325    1.474250   \n",
       "max         0.304000                0.097440    2.873000    4.885000   \n",
       "\n",
       "       perimeter_se     area_se  smoothness_se  compactness_se  concavity_se  \\\n",
       "count    568.000000  568.000000     568.000000      568.000000    568.000000   \n",
       "mean       2.855984   40.138025       0.007042        0.025437      0.031855   \n",
       "std        2.009288   45.282406       0.003005        0.017897      0.030199   \n",
       "min        0.757000    6.802000       0.001713        0.002252      0.000000   \n",
       "25%        1.605000   17.850000       0.005166        0.013048      0.015062   \n",
       "50%        2.285500   24.485000       0.006374        0.020435      0.025875   \n",
       "75%        3.336750   45.017500       0.008151        0.032218      0.041765   \n",
       "max       21.980000  542.200000       0.031130        0.135400      0.396000   \n",
       "\n",
       "       concave points_se  symmetry_se  fractal_dimension_se  radius_worst  \\\n",
       "count         568.000000   568.000000            568.000000     568.00000   \n",
       "mean            0.011789     0.020526              0.003791      16.25315   \n",
       "std             0.006173     0.008264              0.002646       4.82232   \n",
       "min             0.000000     0.007882              0.000895       7.93000   \n",
       "25%             0.007634     0.015128              0.002244      13.01000   \n",
       "50%             0.010920     0.018725              0.003162      14.96500   \n",
       "75%             0.014710     0.023397              0.004526      18.76750   \n",
       "max             0.052790     0.078950              0.029840      36.04000   \n",
       "\n",
       "       texture_worst  perimeter_worst   area_worst  smoothness_worst  \\\n",
       "count     568.000000       568.000000   568.000000        568.000000   \n",
       "mean       25.691919       107.125053   878.578873          0.132316   \n",
       "std         6.141662        33.474687   567.846267          0.022818   \n",
       "min        12.020000        50.410000   185.200000          0.071170   \n",
       "25%        21.095000        84.102500   514.975000          0.116600   \n",
       "50%        25.425000        97.655000   685.550000          0.131300   \n",
       "75%        29.757500       125.175000  1073.500000          0.146000   \n",
       "max        49.540000       251.200000  4254.000000          0.222600   \n",
       "\n",
       "       compactness_worst  concavity_worst  concave points_worst  \\\n",
       "count         568.000000       568.000000            568.000000   \n",
       "mean            0.253541         0.271414              0.114341   \n",
       "std             0.156523         0.207989              0.065484   \n",
       "min             0.027290         0.000000              0.000000   \n",
       "25%             0.146900         0.114475              0.064730   \n",
       "50%             0.211850         0.226550              0.099840   \n",
       "75%             0.337600         0.381400              0.161325   \n",
       "max             1.058000         1.252000              0.291000   \n",
       "\n",
       "       symmetry_worst  fractal_dimension_worst  \n",
       "count      568.000000               568.000000  \n",
       "mean         0.289776                 0.083884  \n",
       "std          0.061508                 0.018017  \n",
       "min          0.156500                 0.055040  \n",
       "25%          0.250350                 0.071412  \n",
       "50%          0.282050                 0.080015  \n",
       "75%          0.317675                 0.092065  \n",
       "max          0.663800                 0.207500  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[1:].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d28a9ce8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (10,5))\n",
    "sns.countplot(df['diagnosis'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d057b3a9",
   "metadata": {},
   "source": [
    "**We have 357 Benign and 212 malignant cancer class in the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba0a9da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.values[:, 1:]\n",
    "y = df.values[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a54ed009",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2, random_state= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f055cf67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((455, 30), (455,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7de6e4f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((114, 30), (114,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ffb34c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the values\n",
    "\n",
    "sc = StandardScaler()\n",
    "\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ea6fdf",
   "metadata": {},
   "source": [
    "**Building ANN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0a68d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                496       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 785\n",
      "Trainable params: 785\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Flatten(input_shape = (30,)))\n",
    "\n",
    "model.add(Dense(16, kernel_initializer = 'random_uniform', activation='relu'))\n",
    "\n",
    "model.add(Dense(16, activation='relu'))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))        \n",
    "\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'binary_crossentropy',\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82275c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "15/15 [==============================] - 1s 52ms/step - loss: 0.6643 - accuracy: 0.7933 - val_loss: 0.5703 - val_accuracy: 0.9561\n",
      "\n",
      "Epoch 00001: loss improved from inf to 0.64179, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.5379 - accuracy: 0.9335 - val_loss: 0.4268 - val_accuracy: 0.9298\n",
      "\n",
      "Epoch 00002: loss improved from 0.64179 to 0.50460, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3875 - accuracy: 0.9419 - val_loss: 0.3213 - val_accuracy: 0.9298\n",
      "\n",
      "Epoch 00003: loss improved from 0.50460 to 0.36866, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.2751 - accuracy: 0.9590 - val_loss: 0.2517 - val_accuracy: 0.9211\n",
      "\n",
      "Epoch 00004: loss improved from 0.36866 to 0.27231, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.2244 - accuracy: 0.9578 - val_loss: 0.2010 - val_accuracy: 0.9211\n",
      "\n",
      "Epoch 00005: loss improved from 0.27231 to 0.20781, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.1642 - accuracy: 0.9666 - val_loss: 0.1664 - val_accuracy: 0.9386\n",
      "\n",
      "Epoch 00006: loss improved from 0.20781 to 0.16397, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.1411 - accuracy: 0.9756 - val_loss: 0.1415 - val_accuracy: 0.9474\n",
      "\n",
      "Epoch 00007: loss improved from 0.16397 to 0.13482, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.1283 - accuracy: 0.9657 - val_loss: 0.1251 - val_accuracy: 0.9737\n",
      "\n",
      "Epoch 00008: loss improved from 0.13482 to 0.11473, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0968 - accuracy: 0.9808 - val_loss: 0.1135 - val_accuracy: 0.9737\n",
      "\n",
      "Epoch 00009: loss improved from 0.11473 to 0.10227, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0800 - accuracy: 0.9828 - val_loss: 0.1064 - val_accuracy: 0.9737\n",
      "\n",
      "Epoch 00010: loss improved from 0.10227 to 0.09247, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0995 - accuracy: 0.9769 - val_loss: 0.1010 - val_accuracy: 0.9649\n",
      "\n",
      "Epoch 00011: loss improved from 0.09247 to 0.08619, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0896 - accuracy: 0.9813 - val_loss: 0.0990 - val_accuracy: 0.9649\n",
      "\n",
      "Epoch 00012: loss improved from 0.08619 to 0.08044, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0900 - accuracy: 0.9766 - val_loss: 0.0948 - val_accuracy: 0.9649\n",
      "\n",
      "Epoch 00013: loss improved from 0.08044 to 0.07642, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0709 - accuracy: 0.9887 - val_loss: 0.0930 - val_accuracy: 0.9649\n",
      "\n",
      "Epoch 00014: loss improved from 0.07642 to 0.07257, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0750 - accuracy: 0.9850 - val_loss: 0.0911 - val_accuracy: 0.9649\n",
      "\n",
      "Epoch 00015: loss improved from 0.07257 to 0.06945, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0742 - accuracy: 0.9891 - val_loss: 0.0901 - val_accuracy: 0.9561\n",
      "\n",
      "Epoch 00016: loss improved from 0.06945 to 0.06641, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0551 - accuracy: 0.9900 - val_loss: 0.0888 - val_accuracy: 0.9561\n",
      "\n",
      "Epoch 00017: loss improved from 0.06641 to 0.06379, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0583 - accuracy: 0.9893 - val_loss: 0.0863 - val_accuracy: 0.9649\n",
      "\n",
      "Epoch 00018: loss improved from 0.06379 to 0.06148, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0659 - accuracy: 0.9872 - val_loss: 0.0859 - val_accuracy: 0.9649\n",
      "\n",
      "Epoch 00019: loss improved from 0.06148 to 0.05967, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0799 - accuracy: 0.9841 - val_loss: 0.0861 - val_accuracy: 0.9649\n",
      "\n",
      "Epoch 00020: loss improved from 0.05967 to 0.05789, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0388 - accuracy: 0.9917 - val_loss: 0.0868 - val_accuracy: 0.9737\n",
      "\n",
      "Epoch 00021: loss improved from 0.05789 to 0.05667, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0545 - accuracy: 0.9911 - val_loss: 0.0874 - val_accuracy: 0.9649\n",
      "\n",
      "Epoch 00022: loss improved from 0.05667 to 0.05497, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0498 - accuracy: 0.9873 - val_loss: 0.0876 - val_accuracy: 0.9649\n",
      "\n",
      "Epoch 00023: loss improved from 0.05497 to 0.05325, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0521 - accuracy: 0.9889 - val_loss: 0.0881 - val_accuracy: 0.9649\n",
      "\n",
      "Epoch 00024: loss improved from 0.05325 to 0.05210, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0446 - accuracy: 0.9912 - val_loss: 0.0898 - val_accuracy: 0.9649\n",
      "\n",
      "Epoch 00025: loss improved from 0.05210 to 0.05088, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0301 - accuracy: 0.9962 - val_loss: 0.0871 - val_accuracy: 0.9561\n",
      "\n",
      "Epoch 00026: loss improved from 0.05088 to 0.04982, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0578 - accuracy: 0.9883 - val_loss: 0.0901 - val_accuracy: 0.9649\n",
      "\n",
      "Epoch 00027: loss improved from 0.04982 to 0.04860, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0430 - accuracy: 0.9905 - val_loss: 0.0919 - val_accuracy: 0.9561\n",
      "\n",
      "Epoch 00028: loss improved from 0.04860 to 0.04733, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0434 - accuracy: 0.9891 - val_loss: 0.0948 - val_accuracy: 0.9649\n",
      "\n",
      "Epoch 00029: loss improved from 0.04733 to 0.04641, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0390 - accuracy: 0.9912 - val_loss: 0.0953 - val_accuracy: 0.9561\n",
      "\n",
      "Epoch 00030: loss improved from 0.04641 to 0.04542, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0315 - accuracy: 0.9947 - val_loss: 0.0958 - val_accuracy: 0.9561\n",
      "\n",
      "Epoch 00031: loss improved from 0.04542 to 0.04463, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0299 - accuracy: 0.9941 - val_loss: 0.0969 - val_accuracy: 0.9561\n",
      "\n",
      "Epoch 00032: loss improved from 0.04463 to 0.04383, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0486 - accuracy: 0.9884 - val_loss: 0.0993 - val_accuracy: 0.9561\n",
      "\n",
      "Epoch 00033: loss improved from 0.04383 to 0.04327, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0344 - accuracy: 0.9933 - val_loss: 0.0991 - val_accuracy: 0.9561\n",
      "\n",
      "Epoch 00034: loss improved from 0.04327 to 0.04228, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0363 - accuracy: 0.9903 - val_loss: 0.1007 - val_accuracy: 0.9561\n",
      "\n",
      "Epoch 00035: loss improved from 0.04228 to 0.04109, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0355 - accuracy: 0.9932 - val_loss: 0.1024 - val_accuracy: 0.9561\n",
      "\n",
      "Epoch 00036: loss improved from 0.04109 to 0.04049, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0539 - accuracy: 0.9805 - val_loss: 0.1048 - val_accuracy: 0.9561\n",
      "\n",
      "Epoch 00037: loss improved from 0.04049 to 0.03999, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0394 - accuracy: 0.9899 - val_loss: 0.1064 - val_accuracy: 0.9561\n",
      "\n",
      "Epoch 00038: loss improved from 0.03999 to 0.03930, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0392 - accuracy: 0.9888 - val_loss: 0.1100 - val_accuracy: 0.9561\n",
      "\n",
      "Epoch 00039: loss improved from 0.03930 to 0.03845, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0328 - accuracy: 0.9938 - val_loss: 0.1088 - val_accuracy: 0.9561\n",
      "\n",
      "Epoch 00040: loss improved from 0.03845 to 0.03809, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0303 - accuracy: 0.9940 - val_loss: 0.1121 - val_accuracy: 0.9561\n",
      "\n",
      "Epoch 00041: loss improved from 0.03809 to 0.03707, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0363 - accuracy: 0.9927 - val_loss: 0.1144 - val_accuracy: 0.9561\n",
      "\n",
      "Epoch 00042: loss improved from 0.03707 to 0.03643, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0418 - accuracy: 0.9886 - val_loss: 0.1146 - val_accuracy: 0.9561\n",
      "\n",
      "Epoch 00043: loss improved from 0.03643 to 0.03570, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0470 - accuracy: 0.9866 - val_loss: 0.1170 - val_accuracy: 0.9561\n",
      "\n",
      "Epoch 00044: loss improved from 0.03570 to 0.03512, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0254 - accuracy: 0.9943 - val_loss: 0.1182 - val_accuracy: 0.9561\n",
      "\n",
      "Epoch 00045: loss improved from 0.03512 to 0.03457, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0558 - accuracy: 0.9815 - val_loss: 0.1228 - val_accuracy: 0.9561\n",
      "\n",
      "Epoch 00046: loss improved from 0.03457 to 0.03421, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0182 - accuracy: 0.9974 - val_loss: 0.1231 - val_accuracy: 0.9561\n",
      "\n",
      "Epoch 00047: loss improved from 0.03421 to 0.03409, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0226 - accuracy: 0.9951 - val_loss: 0.1249 - val_accuracy: 0.9561\n",
      "\n",
      "Epoch 00048: loss improved from 0.03409 to 0.03282, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0279 - accuracy: 0.9936 - val_loss: 0.1256 - val_accuracy: 0.9561\n",
      "\n",
      "Epoch 00049: loss improved from 0.03282 to 0.03247, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0313 - accuracy: 0.9912 - val_loss: 0.1241 - val_accuracy: 0.9561\n",
      "\n",
      "Epoch 00050: loss improved from 0.03247 to 0.03183, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0396 - accuracy: 0.9873 - val_loss: 0.1294 - val_accuracy: 0.9561\n",
      "\n",
      "Epoch 00051: loss improved from 0.03183 to 0.03115, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0334 - accuracy: 0.9901 - val_loss: 0.1286 - val_accuracy: 0.9561\n",
      "\n",
      "Epoch 00052: loss improved from 0.03115 to 0.03053, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0391 - accuracy: 0.9874 - val_loss: 0.1317 - val_accuracy: 0.9561\n",
      "\n",
      "Epoch 00053: loss improved from 0.03053 to 0.03014, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0244 - accuracy: 0.9943 - val_loss: 0.1333 - val_accuracy: 0.9561\n",
      "\n",
      "Epoch 00054: loss improved from 0.03014 to 0.02975, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0238 - accuracy: 0.9932 - val_loss: 0.1324 - val_accuracy: 0.9561\n",
      "\n",
      "Epoch 00055: loss improved from 0.02975 to 0.02908, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0214 - accuracy: 0.9943 - val_loss: 0.1356 - val_accuracy: 0.9561\n",
      "\n",
      "Epoch 00056: loss improved from 0.02908 to 0.02869, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0280 - accuracy: 0.9900 - val_loss: 0.1373 - val_accuracy: 0.9561\n",
      "\n",
      "Epoch 00057: loss improved from 0.02869 to 0.02827, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0294 - accuracy: 0.9895 - val_loss: 0.1377 - val_accuracy: 0.9561\n",
      "\n",
      "Epoch 00058: loss improved from 0.02827 to 0.02767, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0208 - accuracy: 0.9940 - val_loss: 0.1394 - val_accuracy: 0.9561\n",
      "\n",
      "Epoch 00059: loss improved from 0.02767 to 0.02766, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0169 - accuracy: 0.9966 - val_loss: 0.1415 - val_accuracy: 0.9561\n",
      "\n",
      "Epoch 00060: loss improved from 0.02766 to 0.02714, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0237 - accuracy: 0.9929 - val_loss: 0.1433 - val_accuracy: 0.9561\n",
      "\n",
      "Epoch 00061: loss improved from 0.02714 to 0.02658, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0249 - accuracy: 0.9922 - val_loss: 0.1434 - val_accuracy: 0.9561\n",
      "\n",
      "Epoch 00062: loss improved from 0.02658 to 0.02609, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0157 - accuracy: 0.9962 - val_loss: 0.1458 - val_accuracy: 0.9561\n",
      "\n",
      "Epoch 00063: loss improved from 0.02609 to 0.02589, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0284 - accuracy: 0.9912 - val_loss: 0.1457 - val_accuracy: 0.9561\n",
      "\n",
      "Epoch 00064: loss improved from 0.02589 to 0.02582, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0412 - accuracy: 0.9837 - val_loss: 0.1483 - val_accuracy: 0.9561\n",
      "\n",
      "Epoch 00065: loss improved from 0.02582 to 0.02568, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0219 - accuracy: 0.9918 - val_loss: 0.1507 - val_accuracy: 0.9561\n",
      "\n",
      "Epoch 00066: loss improved from 0.02568 to 0.02467, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0161 - accuracy: 0.9965 - val_loss: 0.1520 - val_accuracy: 0.9561\n",
      "\n",
      "Epoch 00067: loss improved from 0.02467 to 0.02443, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0210 - accuracy: 0.9936 - val_loss: 0.1562 - val_accuracy: 0.9561\n",
      "\n",
      "Epoch 00068: loss improved from 0.02443 to 0.02374, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0150 - accuracy: 0.9966 - val_loss: 0.1564 - val_accuracy: 0.9561\n",
      "\n",
      "Epoch 00069: loss improved from 0.02374 to 0.02365, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0154 - accuracy: 0.9957 - val_loss: 0.1574 - val_accuracy: 0.9561\n",
      "\n",
      "Epoch 00070: loss improved from 0.02365 to 0.02279, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0200 - accuracy: 0.9929 - val_loss: 0.1575 - val_accuracy: 0.9561\n",
      "\n",
      "Epoch 00071: loss did not improve from 0.02279\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0181 - accuracy: 0.9956 - val_loss: 0.1509 - val_accuracy: 0.9561\n",
      "\n",
      "Epoch 00072: loss did not improve from 0.02279\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0234 - accuracy: 0.9906 - val_loss: 0.1602 - val_accuracy: 0.9561\n",
      "\n",
      "Epoch 00073: loss improved from 0.02279 to 0.02187, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0135 - accuracy: 0.9963 - val_loss: 0.1588 - val_accuracy: 0.9561\n",
      "\n",
      "Epoch 00074: loss improved from 0.02187 to 0.02177, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0292 - accuracy: 0.9858 - val_loss: 0.1617 - val_accuracy: 0.9561\n",
      "\n",
      "Epoch 00075: loss improved from 0.02177 to 0.02132, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0182 - accuracy: 0.9940 - val_loss: 0.1602 - val_accuracy: 0.9561\n",
      "\n",
      "Epoch 00076: loss improved from 0.02132 to 0.02030, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0297 - accuracy: 0.9848 - val_loss: 0.1680 - val_accuracy: 0.9561\n",
      "\n",
      "Epoch 00077: loss improved from 0.02030 to 0.02011, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0181 - accuracy: 0.9932 - val_loss: 0.1628 - val_accuracy: 0.9561\n",
      "\n",
      "Epoch 00078: loss improved from 0.02011 to 0.01922, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0125 - accuracy: 0.9953 - val_loss: 0.1673 - val_accuracy: 0.9561\n",
      "\n",
      "Epoch 00079: loss improved from 0.01922 to 0.01891, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0250 - accuracy: 0.9893 - val_loss: 0.1689 - val_accuracy: 0.9561\n",
      "\n",
      "Epoch 00080: loss improved from 0.01891 to 0.01837, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0170 - accuracy: 0.9937 - val_loss: 0.1669 - val_accuracy: 0.9561\n",
      "\n",
      "Epoch 00081: loss improved from 0.01837 to 0.01786, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0127 - accuracy: 0.9958 - val_loss: 0.1678 - val_accuracy: 0.9561\n",
      "\n",
      "Epoch 00082: loss improved from 0.01786 to 0.01769, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0259 - accuracy: 0.9878 - val_loss: 0.1702 - val_accuracy: 0.9561\n",
      "\n",
      "Epoch 00083: loss improved from 0.01769 to 0.01722, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0145 - accuracy: 0.9942 - val_loss: 0.1659 - val_accuracy: 0.9561\n",
      "\n",
      "Epoch 00084: loss improved from 0.01722 to 0.01680, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0176 - accuracy: 0.9929 - val_loss: 0.1689 - val_accuracy: 0.9561\n",
      "\n",
      "Epoch 00085: loss improved from 0.01680 to 0.01632, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0163 - accuracy: 0.9921 - val_loss: 0.1692 - val_accuracy: 0.9561\n",
      "\n",
      "Epoch 00086: loss improved from 0.01632 to 0.01602, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0129 - accuracy: 0.9953 - val_loss: 0.1725 - val_accuracy: 0.9561\n",
      "\n",
      "Epoch 00087: loss improved from 0.01602 to 0.01556, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0123 - accuracy: 0.9954 - val_loss: 0.1702 - val_accuracy: 0.9561\n",
      "\n",
      "Epoch 00088: loss improved from 0.01556 to 0.01551, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0196 - accuracy: 0.9885 - val_loss: 0.1722 - val_accuracy: 0.9561\n",
      "\n",
      "Epoch 00089: loss improved from 0.01551 to 0.01483, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0183 - accuracy: 0.9882 - val_loss: 0.1696 - val_accuracy: 0.9561\n",
      "\n",
      "Epoch 00090: loss improved from 0.01483 to 0.01423, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0123 - accuracy: 0.9939 - val_loss: 0.1700 - val_accuracy: 0.9561\n",
      "\n",
      "Epoch 00091: loss improved from 0.01423 to 0.01404, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0174 - accuracy: 0.9913 - val_loss: 0.1698 - val_accuracy: 0.9561\n",
      "\n",
      "Epoch 00092: loss improved from 0.01404 to 0.01366, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0118 - accuracy: 0.9950 - val_loss: 0.1683 - val_accuracy: 0.9561\n",
      "\n",
      "Epoch 00093: loss improved from 0.01366 to 0.01304, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0100 - accuracy: 0.9962 - val_loss: 0.1714 - val_accuracy: 0.9561\n",
      "\n",
      "Epoch 00094: loss improved from 0.01304 to 0.01271, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0099 - accuracy: 0.9966 - val_loss: 0.1703 - val_accuracy: 0.9649\n",
      "\n",
      "Epoch 00095: loss improved from 0.01271 to 0.01242, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0121 - accuracy: 0.9956 - val_loss: 0.1698 - val_accuracy: 0.9649\n",
      "\n",
      "Epoch 00096: loss improved from 0.01242 to 0.01233, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0117 - accuracy: 0.9947 - val_loss: 0.1682 - val_accuracy: 0.9561\n",
      "\n",
      "Epoch 00097: loss improved from 0.01233 to 0.01181, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0100 - accuracy: 0.9987 - val_loss: 0.1710 - val_accuracy: 0.9649\n",
      "\n",
      "Epoch 00098: loss did not improve from 0.01181\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0111 - accuracy: 0.9952 - val_loss: 0.1717 - val_accuracy: 0.9561\n",
      "\n",
      "Epoch 00099: loss improved from 0.01181 to 0.01122, saving model to ANN_BreastCancer.hdf5\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0076 - accuracy: 0.9980 - val_loss: 0.1683 - val_accuracy: 0.9561\n",
      "\n",
      "Epoch 00100: loss improved from 0.01122 to 0.01083, saving model to ANN_BreastCancer.hdf5\n"
     ]
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint(\"ANN_BreastCancer.hdf5\", monitor='loss', verbose=1, save_best_only=True, mode='auto')\n",
    "\n",
    "history = model.fit(X_train, y_train, validation_data= (X_test, y_test), epochs= 100, \n",
    "                    verbose = 1, callbacks= [checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a6ef937",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = model.layers[3].get_weights()[0]\n",
    "biases = model.layers[3].get_weights()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "25556907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last Weights:  [[ 0.3405184 ]\n",
      " [-0.6336784 ]\n",
      " [ 0.59853566]\n",
      " [-0.55728495]\n",
      " [ 0.6982285 ]\n",
      " [ 0.6039666 ]\n",
      " [ 0.44072187]\n",
      " [-0.49215692]\n",
      " [-0.688033  ]\n",
      " [-0.77210516]\n",
      " [ 0.08595348]\n",
      " [-0.65809333]\n",
      " [-0.7437894 ]\n",
      " [ 0.24911259]\n",
      " [ 0.5085356 ]\n",
      " [ 0.70951134]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Last Weights: \",weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2bd8a851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last Bias:  [-0.0853292]\n"
     ]
    }
   ],
   "source": [
    "print(\"Last Bias: \",biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32c68bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0103 - accuracy: 0.9978\n",
      "4/4 [==============================] - 0s 0s/step - loss: 0.1683 - accuracy: 0.9561\n",
      "\n",
      "Train_Accuracy : 0.998, Test_Accuracy: 0.956\n"
     ]
    }
   ],
   "source": [
    "_, train_acc = model.evaluate(X_train, y_train)\n",
    "_, test_acc = model.evaluate(X_test, y_test)\n",
    "\n",
    "print(\"\\nTrain_Accuracy : %.3f, Test_Accuracy: %.3f\" %(train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d877304c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7cb48e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "\n",
    "for element in y_predict:\n",
    "    if element > 0.5:\n",
    "        y_pred.append(1)\n",
    "    else:\n",
    "        y_pred.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6830a73",
   "metadata": {},
   "source": [
    "**Here, we converting values which comes between 0 to 1. If value comes below 0.5 then our model predict 0-class and if its comes above 0.5 then it'll return 1-class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f70fc339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how our model works\n",
    "\n",
    "y_test[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e3d77459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7a1931f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.94      0.95        47\n",
      "         1.0       0.96      0.97      0.96        67\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dc2d014d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(69.0, 0.5, 'Truth')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_true = y_test, y_pred = y_pred)\n",
    "plt.figure(figsize = (10,7))\n",
    "sns.heatmap(cm, annot=True, fmt='d')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a20dae94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot loss during training\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.title('Model_Loss',size = 15, color = 'r')\n",
    "plt.xlabel('Epochs', size = 10, color = 'b')\n",
    "plt.ylabel('Loss', size = 10, color = 'b')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c8bc2db3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x17951a69fc8>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot Accuracy during training\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(history.history['accuracy'], label='train')\n",
    "plt.plot(history.history['val_accuracy'], label='test')\n",
    "plt.title('Model_Accuracy', size = 15, color= 'r')\n",
    "plt.xlabel('Epochs', size = 10, color = 'b')\n",
    "plt.ylabel('Accuracy', size = 10, color = 'b')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e4f1d5",
   "metadata": {},
   "source": [
    "# Thank You"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
